<div class="wrap">

  <div class="basicHero">
    <h1>Guide to Using Aggregate Analysis of ClinicalTrials.gov (AACT) for Statistical and Aggregate Analysis</h1>
  </div>

</div>

<section class="pointsToConsider">
  <div class="wrap">

    <h2>What is AACT?</h2>

    <p>AACT is the database for Aggregate Analysis of <a target='_blank' href='clinicaltrials.gov'>ClinicalTrials.gov</a>. Version 2 of AACT is a postgreSQL relational database containing information about clinical studies that have been been registered at ClinicalTrials.gov. AACT includes all of the protocol and results data elements for studies that are publicly available at ClinicalTrials.gov. Content is downloaded daily from ClinicalTrials.gov and loaded into AACT.</p>

    <p class='question'> <a target='_blank' href=<%= @analyst_guide %> download>Download a word document</a> containing the   information on this page.</p>

    <h2>What population of studies is represented in AACT?</h2>

    <p>All studies registered and publicly available at ClinicalTrials.gov are included in AACT. The ClinicalTrials.gov was released for the registration of studies on <b>February 29, 2000</b>. The registry accepts interventional studies in which participants are assigned according to a research protocol to receive specific interventions, as well as observational studies. It also includes Expanded Access records which describe the procedure for obtaining an experimental drug or device for patients who are not adequately treated by existing therapy and who are unable to participate in a controlled clinical study.</p>

    <p>The registration of studies and reporting of results and adverse events has been mandated to a large extent by requirements (both legal and institutional) implemented as part of the Food and Drug Administration Amendments Act (FDAAA), as well as by requirements introduced by the International Committee of Medical Journal Editors (<a target='_blank' href='http://www.icmje.org/about-icmje/faqs/clinical-trials-registration/'>ICMJE</a>) and the European Medicines Agency (EMA) regarding registration of clinical studies. Table 1 describes the scope of these requirements.</p>

    <h4>Table 1: Scope of Interventional Studies Covered by Major Reporting Policies*</h4>

  <table id='table1' class='regularDisplay'>
    <tr>
      <th>Policy Requirements</th>
      <th>Registration & Results Reporting Requirements</th>
      <th>Effective Date</th>
    </tr>

    <tr>
      <td><p><a target='_blank' href='http://grants.nih.gov/grants/guide/notice-files/NOT-CA-15-011.html'>NCI Access Policy</a></p></td>
      <td><p>The NCI, NIH, issued its Policy Ensuring Public Availability of Results from NCI-supported Clinical Trials. Generally, for "all initiated or commenced NCI-Supported Interventional Clinical Trials whether extramural or intramural" (Covered Trials), "Final Trial Results are expected to be reported in a publicly accessible manner within 12 months of the Trial's Primary Completion Date regardless of whether the clinical trial was completed as planned or terminated earlier." This policy "will be incorporated as a Term and Condition of the award."</p></td>
      <td><p><b>January, 2015</b></p></td>
  </tr>

  <tr>
    <td><a target='_blank' href='http://www.fda.gov/RegulatoryInformation/Legislation/SignificantAmendmentstotheFDCAct/FoodandDrugAdministrationAmendmentsActof2007/default.htm'>FDAAA</a></td>
    <td>The following must be registered in ClinicalTrials.gov:
      <ul class='regularDisplay'>
        <li>Interventional studies of drugs, biologics, or devices (whether or not approved for marketing)</li>
        <li>Studies phases 2 through 4</li>
        <li>Studies with at least 1 US site or conducted under IND/IDE</li>
      </ul>

      <p>Results and adverse event reporting is required for studies that meet the above registration requirements if they study drugs, biologics, or devices that are approved, licensed, or cleared by the FDA.</p>
    </td>

    <td>
      <b>September 27, 2007.</b> Studies initiated after this date, or with a completion date later than December 25, 2007 are subject to FDAAA requirements. Registration is required no later than 21 days after first patient is enrolled. Results and adverse events must be reported for these studies (if required) within 1 year of completing data collection for the pre-specified primary outcome.
      <br><br>
      <b>September, 2008.</b> Results reporting launched with optional adverse event reporting.
      <br><br>
      <b>September, 2009.</b>  Adverse event information became required.
    </td>
  </tr>

  <tr>
    <td><a target='_blank' href='http://www.icmje.org/about-icmje/faqs/clinical-trials-registration/'>ICMJE</a></td>
    <td>
      Interventional studies of any intervention type, phase, or geographical location must be registered in ClinicalTrials.gov or other approved registry.
      <br>No results reporting requirements.
    </td>
    <td>
      <b>July 1, 2005</b>.  Studies initiated after this date must be registered before first patient enrolled; studies initiated before this date must be retrospectively registered to be considered for publication.
    </td>
  </tr>

  <tr>
    <td><a target='_blank' href='http://www.ema.europa.eu/ema/index.jsp?curl=pages/regulation/general/general_content_000629.jsp&mid=WC0b01ac05808768df'>EMA</a></td>
    <td><p>The following must be registered in ClinicalTrials.gov or other approved registry:
      <ul class='regularDisplay'>
        <li>Interventional studies of drugs or biologics (whether or not approved for marketing)</li>
        <li>Pediatric phase 1 studies;</li>
        <li>Studies in phases 2 through 4</li>
        <li>Studies taking place in at least 1 EU site</li>
      </ul>
      <p>Results reporting required for all studies that meet registration requirements.</p>
    </td>
    <td>
        <p>
          <b>May 1, 2004</b>. <a target='_blank' href='http://www.ema.europa.eu/ema/index.jsp?curl=pages/regulation/general/general_content_000629.jsp&mid=WC0b01ac05808768df'>EMA</a> launched <a target='_blank' href='https://eudract.ema.europa.eu/'>EudraCT</a>
          <br><br>
          <b>March 22, 2011</b>. The <a target='_blank' href='https://www.clinicaltrialsregister.eu/'>EU Clinical Trials Register</a> was launched by the <a target='_blank' href='http://www.ema.europa.eu/ema/index.jsp?curl=pages/regulation/general/general_content_000629.jsp&mid=WC0b01ac05808768df'>EMA</a>
       </p>
    </td>
  </tr>

</table>

<p>* Adapted from <a target='_blank' href="http://www.nejm.org/doi/full/10.1056/NEJMsa1012065#t=article">The ClinicalTrials.gov results database – update and key issues</a>. For complete descriptions of policy requirements, see the references cited. <a target='_blank' href='http://www.ema.europa.eu/ema/index.jsp?curl=pages/regulation/general/general_content_000629.jsp&mid=WC0b01ac05808768df'>EMA</a> denotes European Medicines Agency; EU, European Union; FDAAA, Food and Drug Administration Amendments Act; <a target='_blank' href='http://www.icmje.org/about-icmje/faqs/clinical-trials-registration/'>ICMJE</a>, International Committee of Medical Journal Editors; IDE, investigational device exemption; IND, investigational new drug application, NCI, National Cancer Institute; NIH, National Institutes of Health; US, United States.</p>

    <p>Based on these requirements, the following are examples of characteristics that may influence the likelihood that a study is included in the ClinicalTrials.gov registry:</p>

    <ul class='regularDisplay'>
      <li>Interventional studies are more likely to be registered than observational studies.</li>
      <li>Studies that began before the <a target='_blank' href='http://www.icmje.org/about-icmje/faqs/clinical-trials-registration/'>ICMJE</a> requirement in <b>July, 2005</b> are less likely to be registered, especially if their results are unpublished (e.g., negative studies).</li>
      <li>Studies with drug, biological, or device interventions are more likely to be registered than studies of other interventions.</li>
      <li>Studies with at least one site in the United States or European Union are more likely to be registered than studies with no such sites.</li>
      <li>Studies involving a drug or device that is manufactured in the United States are more likely to be registered than studies involving a drug or device manufactured outside of the United States.</li>
      <li>Studies subject to an IND or IDE are more likely to be registered (i.e., if the study is intended to support approval for marketing in the United States).</li>
      <li>Phase 1 adult drug studies or small feasibility studies of devices are less likely to be registered.</li>
      <li>Studies in pediatric populations may be more likely to be registered.</li>
    </ul>

     <h2>How are unique studies identified in AACT?</h2>

     <p>Studies registered at ClinicalTrials.gov are identified by a unique identifier, the NCT_ID.  Because of the quality assurance measures applied by ClinicalTrials.gov staff on registration entries, we can be reasonably certain that each study (i.e., NCT_ID) entered in ClinialTrials.gov refers to a unique clinical study, however a small number of <a target='_blank' href='http://www.ncbi.nlm.nih.gov/pubmed/17507347'>duplicate records may exist in the database.</a></p>

    <h2>What types of questions can be investigated using ClinicalTrials.gov data?</h2>

    <p>The AACT database contains both ‘study protocol’ and ‘results data’ elements. The protocol (or registration) records describe the study characteristics including sponsor, disease condition, type of intervention, participant eligibility, anticipated enrollment, study design, locations, and outcome measures. Summary results data elements including participant flow, baseline characteristics, outcome results, and frequencies of serious and other adverse events are included in AACT.  The <a target='_blank' href='http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2821287/'>article by Tse et al</a> may be helpful in understanding the components of the basic results that are reported at ClinicalTrials.gov.</p>

    <h2>How can protocol/registration data be used?</h2>

    <p>We anticipate that investigators will use the current database to explore the characteristics of selected subsets of clinical studies (e.g., typical enrollment for a phase 3 study in breast cancer patients), and to compare and contrast these characteristics across different subgroups of studies (e.g., sponsor; device versus drug intervention; or prevention versus treatment).</p>

    <h2>How can results and adverse events data be used?</h2>

    <p>Researchers may be able to use the basic results and adverse events summary data reported at ClinicalTrials.gov for meta-analysis or systematic review (e.g., to compare the efficacy and safety of different types of diabetes therapies).  However, because only a small subset of studies registered at ClinicalTrials.gov are required to report results, the results data from ClinicalTrials.gov will most likely be a useful supplement to traditional data sources used for a meta-analysis or systematic review, such as published and unpublished manuscripts and abstracts, rather than the core data source. Standard techniques for valid meta-analysis or systematic review (e.g., <a target='_blank' href="http://annals.org/article.aspx?articleid=744664">PRISMA statement</a>) should be used when determining how to appropriately identify and aggregate summary data gleaned from ClinicalTrials.gov and/or literature.)</p>

    <h2>How should data elements be interpreted?</h2>

    <p>When interpreting this information, you’re encouraged to refer to the authoritative definitions provided by the National Library of Medicine (NLM). The most recent data element definitions are available on the NLM site for <a target='_blank' href='https://prsinfo.clinicaltrials.gov/definitions.html'>studies</a> and <a target='_blank' href='https://prsinfo.clinicaltrials.gov/results_definitions.html'>results</a> data. Data interpretation may depend on:</p>
    <ul class='regularDisplay'>
      <li><b>How the question was phrased.</b> For example, the definition of “Sponsor” does not necessarily imply that the sponsor is the agency paying for the clinical study, as might be expected from the common use of the term.</li>
      <li><b>Whether the respondent can enter a free-text answer to a specific question, or is restricted to a fixed set of possible responses.</b> Note that the definition of a data element and the available responses may have changed over time. The most recent data element definitions are available at the ClinicalTrials.gov site for <a target='_blank' href='https://prsinfo.clinicaltrials.gov/definitions.html'>study</a> and <a target='_blank' href='https://prsinfo.clinicaltrials.gov/results_definitions.html'>results</a> data. A history of changes through September 2011 for the study definitions can be viewed in the <a href="http://ctti-clinicaltrials.org/files/documents/AACTcomprehensiveDataDictionaryV3_2011.xlsx" download>AACT 2011 Data Dictionary</a>.</li>
      <li><b>Whether there is dependence between fields.</b> Certain data elements need to be interpreted together with other data elements. For example, data elements such as enrollment date and completion date have a companion data element that indicates whether the value in the first field is an anticipated or actual value.</li>
    </ul>

    <p class="note">Note that the study record may be updated by the owner of the record at any time. Fields such as enrollment type may be changed from anticipated to actual, indicating that the value entered now reflects the actual rather than the planned enrollment. When data are downloaded, the result is a snapshot of the database at that particular time point, and the history of changes made to the field is lost.</p>

    <h2>How complete and accurate are the data?</h2>

    <p>The presence of a record in a dataset indicates that information was submitted to ClinicalTrials.gov for at least one element in that data set before the data were downloaded from ClinicalTrials.gov. Some data elements are more/less likely than others to have missing information, depending on several known factors. For example:</p>

    <ul class='regularDisplay'>
      <li><b>The data element being required by the FDAAA and/or the ClinicalTrials.gov website.</b> Refer to NLM's <a target='_blank' href='https://prsinfo.clinicaltrials.gov/definitions.html'>study</a> and <a target='_blank' href='https://prsinfo.clinicaltrials.gov/results_definitions.html'>results</a> data element definitions for specifics regarding these requirements. Requirements may have changed over the history of the ClincalTrials.gov database.</li>
      <li><b>The date when the data element was introduced.</b> Not all data elements were included in the database at the time of its launch in 2000, but were added later. Studies registered after FDAAA when into effect must meet more requirements than studies registered earlier in the life of ClinicalTrials.gov.</li>
      <li><b>The branching structure of questions.</b> The availability of certain questions to the person submitting data depends on answers to previous questions. For example, questions about bio-specimen retention are only available for observational studies. Therefore, interventional studies should be excluded when analyzing data elements pertaining to bio-specimens.</li>
      <li><b>The list of possible answers for data elements with a fixed set of responses.</b> For example, questions that include “N/A” as a possible response are likely to have fewer missing values than questions that do not provide a “N/A” response.</li>
    </ul>

    <p>“Missingness” of data may also depend on other unknown factors. Regardless of the cause of missing data, users of ClinicalTrials.gov data sets are encouraged to specify clearly how missing values and “N/A” values are handled in their statistical analysis. For example, are studies with missing values excluded from statistics summarizing that data element, or are they included? In some cases, missing values may be imputed based on other fields (e.g., if a study has a single arm, it cannot employ a randomized design).</p>

    <p>Although the FDAAA and other requirements do not apply to all fields in the database, users might consider including only studies registered post-FDAAA (September 2007), or studies with a primary completion date after December 2007. This will help to limit the number of missing values across many data elements. Users could also consider annotating data elements used in analysis according to whether or not they are FDAAA-required fields, if the user believes this might affect the extent of missing data.</p>

		<p>Even when the data elements for a particular study are complete, users are cautioned to have modest expectations about their accuracy. In particular, results data posted at ClinicalTrials.gov may not be subject to the same level of critical scrutiny as results published in a peer-reviewed journal. As described by <a target='_blank' href="http://www.nejm.org/doi/full/10.1056/NEJMsa1012065#t=article">Zarin and colleagues in <i>'The ClinicalTrials.gov results database – update and key issues'</i></a>, ClinicalTrials.gov has implemented several measures to ensure data quality. For example, NLM staff apply automated business rules that alert data-providers when required elements are missing or inconsistent. In addition, some manual review is performed by NLM, and a record may be returned to the data-provider if revision is required.  However, ClinicalTrials.gov staff cannot always validate the accuracy of submitted data (e.g., against an independent source).  As Zarin et al. note, “… individual record review has inherent limitations, and posting does not guarantee that the record is fully compliant with either ClinialTrials.gov or legal requirements” <a target='_blank' href="http://www.nejm.org/doi/full/10.1056/NEJMsa1012065#t=article"><sup>[1]</sup></a></p>

    <p>During our own analysis of the ClinicalTrials.gov database, several extreme values for numeric data elements were encountered, such as an anticipated enrollment of several million subjects. Before proceeding with aggregate analysis, users are encouraged to review data distributions in order to select appropriate analysis methods, and to run their own consistency checks (e.g., to compare whether the number of arm descriptions provided for the study matches the data element that quantifies the number of arms in the study design) as needed.</p>

    <h2>Downloaded AACT is a snapshot at one point in time</h2>

    <p>The data downloaded from ClinicalTrials.gov and stored in AACT is a snapshot of the information that was publicly available at ClinicalTrials.gov on the download date.  Data submitters may update their ClinicalTrials.gov study record at any time but a particular instance of AACT only captures the information present at one point in time.  Although changes to a study are stored in an archive history at ClinicalTrials.gov, these changes are not currently captured in a particular version of AACT. </p>

<p class='question'>Should we alter this to reflect how the person may access AACT? If they download it is a snapshot on that date. If the access directly - it is up to date as of the previous day? Or should it be removed and a blurb be placed somewhere else on the AACT2 site?</p>


    <h2>Use of appropriate statistical inference</h2>

    <p>If the AACT results data are to be used to support a meta-analysis or systematic review of the safety or efficacy of a particular intervention, then standard methods of meta-analysis or systematic review (e.g., the <a target='_blank' href="http://annals.org/article.aspx?articleid=744664">PRISMA statement</a> should be used to appropriately account for study-to-study variability and other sources of uncertainty or bias. We recommend that authors consider the following points when deciding whether to report p-values, confidence intervals, or other probability-based inference when performing aggregate analysis of the ClinicalTrials.gov database:  </p>

    <h3>Is the data-generating mechanism random?</h3>
    <p>Methods of statistical inference such as p-values and 95% confidence intervals are most appropriate when used to quantify the uncertainty of estimates or comparisons due to a random process that generates the data. Examples of such processes include selection of a random sample of subjects from a broader population, randomly assigning a treatment to a cohort of subjects, or a coin toss about which we aim to predict future results.</p>

    <p>In the following examples, we recommend against reporting p-values and 95% confidence intervals because the data generating mechanism is not random.</p>

    <p><b> Example 1:</b> Descriptive analysis of studies registered in the ClinicalTrials.gov database. In this case, the “sample” equals the “population” (i.e., the group about which we are making conclusions) and there is no role for statistical inference because there is no sample-vs-population uncertainty to be quantified.</p>

		<p><b>Example 2: </b>Descriptive analysis of the “clinical trials enterprise” as characterized by the studies registered in ClinicalTrials.gov. Despite mandates for study registration <a href="#table1">(Table 1)</a>, it may be that some studies that are required to be registered are not. In this case the sample (studies registered in ClinicalTrials.gov) may not equal the population (clinical trials enterprise). However, it is likely that those studies not registered are not excluded at random, and therefore neither p-values nor confidence intervals are helpful to support extrapolation from the sample to the population. To support such extrapolation, we recommend careful consideration of the studies that are highly likely to be registered (see section above on Population), and to limit inference to this population so that sample-vs-population uncertainty is minimal.</p>

    <h2>How can I objectively identify important differences?</h2>

    <p>In practice, p-values and confidence intervals are often employed even when there is no random data generating process to highlight differences that are larger than “noise” (e.g., authors may want to highlight differences with a p-value < .001).  While this practice may not have a strong foundation in statistical philosophy, we acknowledge that many audiences (e.g., journal peer reviewers) may demand p-values because they appear to provide objective criteria for identifying larger-than-expected signals in the data.  While we don’t encourage reporting of p-values for this purpose, we do encourage analysts to specify objective criteria for evaluating signals in the data.  Examples are provided:</p>

    <p>a) Prior to examining the data, specify comparisons of major interest, or quantities to be estimated. </p>

    <p>b) Determine the magnitude of differences that would have practical significance.  (e.g., a 25% difference in source of funding between studies of 2 pediatric conditions, or a difference in enrollment of 100 participants).  </p>

    <p>c) Determine appropriate formulas for quantifying differences between groups or summarizing population variability.  This quantification could take into account of the observed difference, variability in the data, and the number of observations.  Examples are provided:</p>

    <ul class='regularDisplay'>
      <li>When summarizing a continuous characteristic such as enrollment, the analyst might choose to report the median and 5th to 95th percentiles.</li>
      <li>To quantify signal to noise, the analyst could calculate a t-statistic or a chi-squared statistic (without the p-value) and rank differences between 2 groups based on these values.  The analyst might pre-specify a threshold (e.g., absolute value of 3) to flag notable differences.</li>
    </ul>

    <h2>Specific tips for working with the AACT database</h2>

    <ul class='regularDisplay'>
      <li>Users are encouraged to use the <a href=<%= @schema_diagram %> target="_blank">Schema Diagram</a> to determine relationships between different AACT tables/datasets (referred to as ‘datasets’ on this page). These relationships determine how datasets may be linked or merged together in software such as SAS & SQL.</li>
      <li>The NCT_ID uniquely identifies each study; it serves as the primary key in the STUDIES dataset. In other words, each record in the STUDIES dataset has a unique NCT_ID value. NCT_ID also appears in every dataset related to STUDIES so that every record in every dataset can link back to the study to which it refers.</li>
      <li>Every dataset other than STUDIES has a primary key named ‘id’, which provides an integer that uniquely identifies each row in that dataset. (The STUDIES dataset uses ‘NCT_ID’ instead of ‘id’  as the unique identifier for each row.)</li>
      <li>To link dataset information to the study to which it refers, you simply match on NCT_ID. For example, every record in the CONDITIONS dataset with an NCT_ID of ‘NCT0000001’ refers to the study with the NCT_ID: ‘NCT0000001’ (saved in STUDIES.nct_id). The CONDITIONS dataset may contain multiple records with an NCT_ID of ‘NCT0000001’ which means this study was defined in ClinicalTrials.gov as being associated with the conditions listed in CONDITIONS with that NCT_ID.</li>
      <li>Information in several datasets are also related to information in other datasets. In this case, the dataset that belongs to another dataset will include a foreign key that identifies the record to which it belongs. Foreign keys are always named according to a simple rule: the singular name of the related dataset followed by: ‘_id’.  For example, FACILITY_CONTACTS includes a data element: facility_id which is the foreign key to FACILITY.id</li>
      <li> Each record’s foreign_key (ie. facility_id) contains the value of the unique identifier (id) of the record in the other dataset to which it belongs. For example, a facility may have multiple contacts. To find the contacts for a particular facility, look for the records in FACILITY_CONTACTS where the value in facility_id is same as the value in id for that facility in FACILITIES. In short, datasets are related to each other with this pattern: dataset1.<dataset2_name>_id = dataset2.id </li>
    </ul>
<p class='question'> this section needs a bit more work</p>
    <table class='regularDisplay'>
      <tr>
        <td>facilities.id = facility_contacts.facility_id</td>
        <td>finds all contacts for a facility</td>
      </tr>
      <tr>
        <td>facility_contacts.facility_id = facilities.id</td>
        <td>inversely: finds the facility for a particular contact</td>
      </tr>
    </table>

    <h2>Information about trial sites (FACILITIES and COUNTRIES) </h2>
     <p> Information about organizations (trial sites) where the study is/was conducted is stored in the FACILITIES dataset.  This is a snapshot of the facility information that was included in the study record on the date that information was downloaded from ClinicalTrials.gov.  Naturally, study sites initiated after ClinicalTrials.gov data were downloaded to AACT are not included in AACT.</p>
		<p>AACT also includes a COUNTRIES dataset, which contains one record per unique country per study. Rows in the COUNTRIES dataset come from two sources:</p>
    <ul class='regularDisplay'>
			<li>Countries where study facilities are located as determined by an NLM algorithm that identifies the set of unique countries associated with a study; these are stored in the COUNTRIES dataset with the flag removed=false. </li>
			<li>In some cases, ClinicalTrials.gov data submitters remove sites from the study record.  Removed sites do not appear in the FACILITIES dataset. If all of a country’s sites have been removed from a study record, the NLM algorithm creates a ‘Removed Country’ record. In AACT, this record is stored in the COUNTRIES dataset with removed=true. </li>
		</ul>

    <p>The reasons sites are removed from the FACILITIES dataset are varied but unknown.  A site may have been removed because it was never initiated or because it was entered with incorrect information.  The recommended action for sites that have completed or have terminated enrollment is to change the enrollment status to “Completed” or “Terminated”; however, such sites are sometimes deleted from the study record by the responsible party.  Data analysts may consider using Countries where  removed=TRUE to supplement the information about trial locations that is contained in FACILITIES, particularly for studies that have completed enrollment and have no records in FACILITIES.</p>

    <p>Users who are interested in identifying countries where participants are being/were enrolled may use either the FACILITIES or COUNTRIES dataset (where COUNTRIES.removed=false) with equivalent results.</p>


    <h2>MeSH terms in BROWSE_CONDITIONS and BROWSE_INTERVENTIONS</h2>
    <p>When data submitters provide information to ClinicalTrials.gov about a study, they’re encouraged to use Medical Subject Heading (MeSH) terminology for interventions, conditions, and keywords.  The BROWSE_CONDITIONS and BROWSE_INTERVENTIONS datasets contain MeSH terms generated by an algorithm run by NLM. The NLM algorithm is re-run nightly on all studies in the ClinicalTrials.gov database, and sources the most up-to-date information in the study record, the latest version of the algorithm, and the version of the MeSH thesaurus in use at that time.</p>

    <h2>“Delayed Results” data elements available in AACT</h2>

    <p>A responsible party may delay the deadline for submitting results information to ClinicalTrials.gov if one of the following two certification conditions applies to the trial:</p>

    <ul class='regularDisplay'>
      <li>Initial approval: trial completed before a drug, biologic or device studied in the trial is initially approved, licensed or cleared by the FDA for any use.</li>
      <li>New use: the manufacturer of a drug, biologic or device is the sponsor of the trial and has filed or will file within one year, an application seeking FDA approval, licensure, or clearance of the new use studied in the trial. A responsible party may also request, for good cause, an extension of the deadline for the submission of results.</li>
    </ul>

    <p>Studies for which a certification or extension request have been submitted include the date of the first certification or extension request in the data element: FIRST_RECEIVED_DISPOSITION_DATE.</p>

    <p>In general, the content that is contained in the AACT database preserves the content in the source XML files that are downloaded from ClinicalTrials.gov.</p>

    <h2>References</h2>

    <ol>
      <li>Zarin, D. A., Tse, T. T., Williams, R. J., Califf, R. M., and Ide, N. C. (2011). <a target='_blank' href="http://www.nejm.org/doi/full/10.1056/NEJMsa1012065#t=article">The ClinicalTrials.gov results database – update and key issues</a>. N Engl J Med 364: 852–60.</li>
      <li><a target='_blank' href="http://www.fda.gov/RegulatoryInformation/Legislation/SignificantAmendmentstotheFDCAct/FoodandDrugAdministrationAmendmentsActof2007/default.htm">Food and Drug Administration Amendments Act of 2007</a>. Public Law 110-95.</li>
      <li>Laine, C., Horton R., DeAngelis C.D., et al. <a target='_blank' href="http://www.nejm.org/doi/full/10.1056/NEJMe078110#t=article">Clinical trial registration – looking back and moving ahead</a>. N Engl J Med 356: 2734–6.</li>
      <li><a target='_blank' href="http://ec.europa.eu/health/files/eudralex/vol-10/2008_07/c_16820080703en00030004_en.pdf">Communication from the Commission regarding the guideline on the data fields contained in the clinical trials database provided for in Article 11 of Directive 2001/20/EC to be included in the database on medicinal products provided for in Article 57 or Regulation (EC) No 726/2004</a>. In: European Commission, ed. Official Journal of the European Union, 2008. (2008/C 168/02.)</li>
      <li><a target='_blank' href="http://www.ema.europa.eu/ema/index.jsp?curl=pages/regulation/general/general_content_000044.jsp">Guidance on the information concerning paediatric clinical trials to be entered into the EU Database on Clinical Trials (EudraCT) and on the information to be made public by the European Medicines Agency (EMEA), in accordance with Article 41 of Regulation (EC) No 1901/2006</a>. In: European Commission, ed. Official Journal of the European Union, 2009. (2009/C 28/01.)</li>
      <li>Zarin, D. A., Ide, N. C., Tse, T. et al. (2007). <a target='_blank' href="http://www.ncbi.nlm.nih.gov/pubmed/17507347">Issues in the registration of clinical trials</a>. JAMA 297: 2112—2120.</li>
      <li>Moher, D., Liberati, A., Tetzlaff, J. and Altman, D. G. (for the PRISMA Group)(2009). <a target='_blank' href="http://annals.org/article.aspx?articleid=744664">Preferred reporting items for systematic reviews and meta-analyses: the PRISMA statement</a>, BMJ 339: 332—336.</li>
      <li>Tse, T., Williams, R. J., Zarin, D. A. (2009). <a target='_blank' href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2821287/">Reporting “basic results” in ClinicalTrials.gov</a>. CHEST 136: 295—303.</li>
    </ol>

  </div>
</section>
